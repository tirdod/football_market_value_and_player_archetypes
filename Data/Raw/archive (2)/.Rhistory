install_version("hoopR", "1.2.0")
update.packages(checkBuilt = TRUE)
local({r <- getOption("repos")
r["CRAN"] <- "http://cran.r-project.org"
options(repos=r)
})
local({r <- getOption("repos")
r["CRAN"] <- "http://cran.r-project.org"
options(repos=r)
})
install.packages('hoopR')
library(htmltools)
print('test')
# loading in required packages
if (!require("knitr")) install.packages("knitr"); library(knitr)
if (!require("rmarkdown")) install.packages("rmarkdown"); library(rmarkdown)
# some useful global defaults
opts_chunk$set(warning=FALSE, message=FALSE, include=TRUE, echo=TRUE, cache=FALSE, cache.comments=FALSE, comment='##')
# output specific defaults
output <- opts_knit$get("rmarkdown.pandoc.to")
if (output == "html") opts_chunk$set(fig.width=10, fig.height=5)
output
ouput == 'html'
output == 'html'
# loading in required packages
if (!require("knitr")) install.packages("knitr"); library(knitr)
if (!require("rmarkdown")) install.packages("rmarkdown"); library(rmarkdown)
# some useful global defaults
opts_chunk$set(warning=FALSE, message=FALSE, include=TRUE, echo=TRUE, cache=FALSE, cache.comments=FALSE, comment='##')
# output specific defaults
output <- opts_knit$get("rmarkdown.pandoc.to")
if (output == "html") opts_chunk$set(fig.width=10, fig.height=5)
1 + 2
1 - 2
1 / 2
1 * 2
2 ** 3
sin(5 / 2)
sqrt(2)
a <- 5
a
out <- NULL
for (var in vector) {
if (var %% 2 != 0) {
# your code
}
out <- c(out,var)
even <- function(vector){
out <- NULL
for (var in vector) {
if (var %% 2 != 0) {
# your code
}
out <- c(out,var)
}
return(out)
}
even <- function(vector){
out <- NULL
for (var in vector) {
if (var %% 2 != 0) {
next
}
out <- c(out,var)
}
return(out)
}
View(even)
source('exercises.R')
source('exercises.R')
source('exercises.R')
chr2int <- function(df){
print(df$day)
return(df)
}
print(df)
'2024-08-07' >= '1999-11-05'
devtools::install_github("statsbomb/StatsBombR")
devtools::install_github("FCrSTATS/SBpitch")
library(tidyverse)
library(tidyverse, lib.loc = "/Library/Frameworks/R.framework/Versions/4.1/Resources/library")
library(tidyverse)
library(StatsBombR)
comps <- FreeCompetitions()
premierLeague = Comps %>%
filter(competition_name==2 & season_name==27)
premierLeague = comps %>%
filter(competition_name==2 & season_name==27)
View(premierLeague)
premierLeague = comps %>%
filter(competition_id==2 & season_id==27)
Comps <- Comps
Comps <- comps
View(comps)
matches <- FreeMatches(comps)
View(matches)
StatsBombData <- free_allevents(MatchesDF = Matches, Parallel = T)
StatsBombData <- free_allevents(MatchesDF = matches, Parallel = T)
StatsBombData = allclean(StatsBombData)
StatsBombData <- free_allevents(MatchesDF = matches, Parallel = T)
library(tidyverse)
library(StatsBombR)
comps <- FreeCompetitions()
remove(comps)
Comps <- FreeCompetitions()
Comps = Comps %>%
filter(competition_name=="" & season_name=="")
View(Comps)
Comps <- FreeCompetitions()
Matches <- FreeMatches(Comps)
StatsBombData <- free_allevents(MatchesDF = Matches, Parallel = T)
la_liga = Comps %>%
filter(competition_id==11 & season_id==90)
View(la_liga)
Matches <- FreeMatches(la_liga)
View(Matches)
premier_league = Comps %>%
filter(competition_id==2 & season_id==27)
la_liga_matches <- FreeMatches(la_liga)
premier_league_matches <- FreeMatches(premier_league)
StatsBombData <- free_allevents(MatchesDF = premier_league_matches, Parallel = T)
View(StatsBombData)
StatsBombData = allclean(StatsBombData)
premier_league_data <- allclean(free_allevents(MatchesDF = premier_league_matches, Parallel = T))
View(premier_league_data)
shots_goals = premier_league_data %>%
group_by(team.name) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE),
goals = sum(shot.outcome.name=="Goal", na.rm = TRUE))
View(shots_goals)
shots_goals = StatsBombData %>%
group_by(team.name) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE)/n_distinct(match_id),
goals = sum(shot.outcome.name=="Goal", na.rm = TRUE)/n_distinct(match_id))
shots_goals_total = premier_league_data %>%
group_by(team.name) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE),
goals = sum(shot.outcome.name=="Goal", na.rm = TRUE))
shots_goals_per_game = StatsBombData %>%
group_by(team.name) %>%
summarise(shots_per_game = sum(type.name=="Shot", na.rm = TRUE)/n_distinct(match_id),
goals_per_game = sum(shot.outcome.name=="Goal", na.rm = TRUE)/n_distinct(match_id))
view(shots_goals_per_game)
player_shots_keypasses = premier_league_data %>%
group_by(player.name, player.id) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE),
keypasses = sum(pass.shot_assist==TRUE, na.rm = TRUE))
View(player_shots_keypasses)
player_minutes = get.minutesplayed(premier_league_data)
player_minutes = player_minutes %>%
group_by(player.id) %>%
summarise(minutes = sum(MinutesPlayed))
player_shots_keypasses = left_join(player_shots_keypasses, player_minutes)
player_shots_keypasses = player_shots_keypasses %>% mutate(nineties = minutes/90)
player_shots_keypasses = player_shots_keypasses %>% mutate(shots_per90 =
shots/nineties,
kp_per90 = keypasses/nineties,
shots_kp_per90 = shots_per90+kp_per90)
player_shots_keypasses = player_shots_keypasses %>% filter(minutes>360)
passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name)) %>%
filter(location.x<80 & pass.end_location.x>=80) %>%
group_by(player.name) %>%
summarise(f3_passes = sum(type.name=="Pass"))
View(passes)
View(premier_league_data)
shots_goals = premier_league_data %>%
group_by(team.name) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE),
goals = sum(shot.outcome.name=="Goal", na.rm = TRUE))
View(shots_goals)
shots_goals = premier_league_data %>%
group_by(team.name) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE)/n_distinct(match_id),
goals = sum(shot.outcome.name=="Goal", na.rm = TRUE)/n_distinct(match_id))
library(ggplot2)
ggplot(data = shots_goals,
aes(x = reorder(team.name, shots), y = shots)) +
geom_bar(stat = "identity", width = 0.5) +
labs(y="Shots") +
theme(axis.title.y = element_blank()) +
scale_y_continuous( expand = c(0,0)) +
coord_flip()
ggplot(data = shots_goals,
aes(x = reorder(team.name, shots), y = shots)) +
geom_bar(stat = "identity", width = 0.5) +
labs(y="Shots Per Game") +
theme(axis.title.y = element_blank()) +
scale_y_continuous( expand = c(0,0)) +
coord_flip()
player_shots_keypasses = premier_league_data %>%
group_by(player.name, player.id) %>%
summarise(shots = sum(type.name=="Shot", na.rm = TRUE),
keypasses = sum(pass.shot_assist==TRUE, na.rm = TRUE))
player_minutes = get.minutesplayed(StatsBombData)
ggplot(player_shots_keypasses, aes(x = shots_per90, y = kp_per90,
colour = shots_kp_per90, alpha = 0.9)) +
labs(x = "Shots per 90", y = "Key Passes per 90") +
geom_point(size = 5, show.legend = FALSE) +
geom_text(data = player_shots_keypasses, aes(label = player.name),
colour = "black", size = 5, vjust = -0.5) +
guides(alpha = "none")
player_minutes = get.minutesplayed(premier_league_data)
player_minutes = player_minutes %>%
group_by(player.id) %>%
summarise(minutes = sum(MinutesPlayed))
player_minutes = get.minutesplayed(StatsBombData)
player_minutes = get.minutesplayed(premier_league_data)
player_minutes = player_minutes %>%
group_by(player.id) %>%
summarise(minutes = sum(MinutesPlayed))
player_shots_keypasses = left_join(player_shots_keypasses, player_minutes)
player_shots_keypasses = player_shots_keypasses %>% mutate(nineties = minutes/90)
player_shots_keypasses = player_shots_keypasses %>% mutate(shots_per90 =
shots/nineties,
kp_per90 = keypasses/nineties,
shots_kp_per90 = shots_per90+kp_per90)
player_shots_keypasses = player_shots_keypasses %>% filter(minutes>360)
View(player_shots_keypasses)
ggplot(player_shots_keypasses, aes(x = shots_per90, y = kp_per90,
colour = shots_kp_per90, alpha = 0.9)) +
labs(x = "Shots per 90", y = "Key Passes per 90") +
geom_point(size = 5, show.legend = FALSE) +
geom_text(data = player_shots_keypasses, aes(label = player.name),
colour = "black", size = 5, vjust = -0.5) +
guides(alpha = "none")
library(SBpitch)
passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name)) %>%
filter(location.x<80 & pass.end_location.x>=80) %>%
group_by(player.id, player.name) %>%
summarise(f3_passes = sum(type.name=="Pass"))
player_minutes = get.minutesplayed(premier_league_data)
player_minutes = player_minutes %>%
group_by(player.id) %>%
summarise(minutes = sum(MinutesPlayed))
#Join Minutes Played Data To Player Shots Dataframe
passes = left_join(passes, player_minutes)
passes = passes %>% mutate(nineties = minutes/90)
passes = passes %>% mutate(f3passes_per90 = f3_passes/nineties)
#filter minutes
passes = passes %>% filter(minutes>360) %>%
arrange(desc(f3passes_per90))
player_passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name) & player.name=="") %>%
filter(location.x<80 & pass.end_location.x>=80)
View(passes)
create_Pitch() +
geom_segment(data = player_passes, aes(x = location.x, y = location.y,
xend = pass.end_location.x, yend = pass.end_location.y),
lineend = "round", linewidth = 0.5, colour = "#000000",
arrow = arrow(length = unit(0.07, "inches"), ends = "last", type = "open")) +
labs(title = "Player Name, Passes to the final third", subtitle = "Competition") +
scale_y_reverse() +
coord_fixed(ratio = 105/100)
View(player_passes)
player_passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name) & player.name=="") %>%
filter(location.x<80 & pass.end_location.x>=80)
player_minutes = get.minutesplayed(premier_league_data)
player_minutes = player_minutes %>%
group_by(player.id) %>%
summarise(minutes = sum(MinutesPlayed))
#Join Minutes Played Data To Player Shots Dataframe
passes = left_join(passes, player_minutes)
passes = passes %>% mutate(nineties = minutes/90)
passes = passes %>% mutate(f3passes_per90 = f3_passes/nineties)
#filter minutes
passes = passes %>% filter(minutes>360) %>%
arrange(desc(f3passes_per90))
player_passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name) & player.name=="") %>%
filter(location.x<80 & pass.end_location.x>=80)
create_Pitch() +
geom_segment(data = player_passes, aes(x = location.x, y = location.y,
xend = pass.end_location.x, yend = pass.end_location.y),
lineend = "round", linewidth = 0.5, colour = "#000000",
arrow = arrow(length = unit(0.07, "inches"), ends = "last", type = "open")) +
labs(title = "Player Name, Passes to the final third", subtitle = "Competition") +
scale_y_reverse() +
coord_fixed(ratio = 105/100)
player_passes = premier_league_data %>%
filter(type.name=="Pass" & is.na(pass.outcome.name) & player.name=="Mesut Özil") %>%
filter(location.x<80 & pass.end_location.x>=80)
create_Pitch() +
geom_segment(data = player_passes, aes(x = location.x, y = location.y,
xend = pass.end_location.x, yend = pass.end_location.y),
lineend = "round", linewidth = 0.5, colour = "#000000",
arrow = arrow(length = unit(0.07, "inches"), ends = "last", type = "open")) +
labs(title = "Mesut Özil, Passes to the final third", subtitle = "Premier League 2015-16") +
scale_y_reverse() +
coord_fixed(ratio = 105/100)
create_Pitch() +
geom_segment(data = player_shots_keypasses, aes(x = location.x, y = location.y,
xend = pass.end_location.x, yend = pass.end_location.y),
lineend = "round", linewidth = 0.5, colour = "#000000",
arrow = arrow(length = unit(0.07, "inches"), ends = "last", type = "open")) +
labs(title = "Mesut Özil, Passes Key Passes", subtitle = "Premier League 2015-16") +
scale_y_reverse() +
coord_fixed(ratio = 105/100)
create_Pitch() +
geom_segment(data = player_passes, aes(x = location.x, y = location.y,
xend = pass.end_location.x, yend = pass.end_location.y),
lineend = "round", linewidth = 0.5, colour = "#000000",
arrow = arrow(length = unit(0.07, "inches"), ends = "last", type = "open")) +
labs(title = "Mesut Özil, Passes to the final third", subtitle = "Premier League 2015-16") +
scale_y_reverse() +
coord_fixed(ratio = 105/100)
### Homework 3 [Exercise 2.3]
### Author: Maxim Fedotov (maxim.fedotov@upf.edu)
### Course: Statistical Modeling and Inference [part 2]
### Professor: Geert Mesters
# Parameters [Do not change]
#   Here we define the parameters of the Poisson components, `lambda`, and
#   the mixing coefficients, `mix.prob`.
#
#   We suppose that there are two types of viruses in question, and one of them
#   is much more prone to mutation.
n <- 300
K <- 2
lambda.true <- c(3, 10)
p.mix.1.true <- 0.8
p.mix.true <- c(p.mix.1.true, 1 - p.mix.1.true)
# 2.3.1. Data simulation.
#   In this part the goal is to sample a random vector `x` from the Poisson
#   mixture model with the mixture probabilities defined in `p.mix.true` and
#   the parameters of the components defined in `lambda.true`.
set.seed(100) # set seed first
#   [1] Sample a vector of categorical random variables which take values
#       from `lambda.true` with probabilities defined in `p.mix.true`.
z <- sample(1:K, size=n, replace=TRUE, prob=p.mix.true)
#   [2] Sample a vector of Poisson variables such that for the i-th observation
#       x_i follows Poisson distribution with parameter lambda.true[z_i]).
x <- rpois(n, lambda=true[z])
### Homework 3 [Exercise 2.3]
### Author: Maxim Fedotov (maxim.fedotov@upf.edu)
### Course: Statistical Modeling and Inference [part 2]
### Professor: Geert Mesters
# Parameters [Do not change]
#   Here we define the parameters of the Poisson components, `lambda`, and
#   the mixing coefficients, `mix.prob`.
#
#   We suppose that there are two types of viruses in question, and one of them
#   is much more prone to mutation.
n <- 300
K <- 2
lambda.true <- c(3, 10)
p.mix.1.true <- 0.8
p.mix.true <- c(p.mix.1.true, 1 - p.mix.1.true)
# 2.3.1. Data simulation.
#   In this part the goal is to sample a random vector `x` from the Poisson
#   mixture model with the mixture probabilities defined in `p.mix.true` and
#   the parameters of the components defined in `lambda.true`.
set.seed(100) # set seed first
#   [1] Sample a vector of categorical random variables which take values
#       from `lambda.true` with probabilities defined in `p.mix.true`.
z <- sample(1:K, size=n, replace=TRUE, prob=p.mix.true)
#   [2] Sample a vector of Poisson variables such that for the i-th observation
#       x_i follows Poisson distribution with parameter lambda.true[z_i]).
x <- rpois(n, lambda.true[z])
# Check out what you've got:
hist(x, breaks = seq(min(x) - 0.5, max(x) + 0.5, by=1))
# EM-algorithm
#   This section is split into short parts. You shall write
#       1. A routine for E-step.
#       2. A routine for M-step.
#       3. A function which utilizes these routines running the whole
#          EM-algorithm until convergence.
#   2.3.2. E-step
#       Define a function `e.step`. You may also define auxiliary functions if
#       you need to.
#           Arguments:
#               `x`         -- the data vector
#               `lambda`    -- the value of the Poisson parameters supplied to
#                              the current step
#               `p.mix`     -- the value of the mixing probabilities supplied to
#                              the current step
#           Output:
#               A matrix `G` of size n x K such that G[i, k] corresponds to
#               gamma_{i, k} := p(z_i = k | x_i, lambda, p.mix).
e.step <- function(x, lambda, p.mix) {
stopifnot(length(lambda) == length(p.mix))
n <- length(x)
K <- length(lambda)
G <- matrix(0, n, K)
for (k in 1:K) {
G[, k] <- p.mix[k] * (lambda[k]^x) * exp(-lambda[k])
}
G <- G / rowSums(G)  # Normalize rows to ensure probabilities sum to 1
return(G)
}
# 2.3.3. M-step
#   [1] Define a function `log.lik.comp` which computes the log-likelihood for
#       the whole sample as described in equation (1) from the pdf file using
#       `lambda` for the components parameters and `p.mix` for the mixing
#       coefficients.
#       Arguments:
#           `x`         -- the data vector
#           `lambda`    -- the value of the Poisson parameters supplied to
#                          the current step
#           `p.mix`     -- the value of the mixing probabilities supplied to
#                          the current step
#       Output:
#           The log likelihood value.
log.lik.comp <- function(x, lambda, p.mix) {
stopifnot(length(lambda) == length(p.mix))
log.lik <- sum(log(rowSums(sapply(1:length(lambda), function(k) {
p.mix[k] * (lambda[k]^x) * exp(-lambda[k])
}))))
return(log.lik)
}
#   [2] Define a function `m.step`.
#       Arguments:
#           `x`, `G`
#       Output:
#           A list with elements `lambda`, `p.mix`, and `log.lik`.
#           The first two are the updated values of the model parameters in
#           the "maximization" step of the EM algorithm. The `log.lik`
#           is a log-likelihood value.
m.step <- function(x, G) {
stopifnot(length(x) == dim(G)[1])
# Compute `lambda` and `p.mix` based on the formulas that you obtained in
# Exercise 2.2 and the output of e.step function, `G`.
lambda <- colSums(G * x) / colSums(G)
p.mix <- colSums(G) / length(x)
# Compute the log likelihood value.
log.lik <- log.lik.comp(x, lambda, p.mix)
return(
list(lambda=lambda, p.mix=p.mix, log.lik=log.lik)
)
}
# 2.3.4. Complete and run the EM algorithm
#   [1] Complete the function below
em.alg <- function(x, lambda.init, p.mix.init, maxit=100, tol=10^(-6)) {
# Initialize lambda, p.mix, and compute the corresponding log.lik.
lambda <- lambda.init
p.mix <- p.mix.init
log.lik <- log.lik.comp(x, lambda, p.mix)
# Iterate until the maximum number of iterations.
for (j in 1:maxit) {
log.lik.prev <- log.lik
# Run the e.step
G <- e.step(x, lambda, p.mix)
# Run the m.step
result <- m.step(x, G)
# Update the parameters and the log-likelihood value.
lambda <- result$lambda
p.mix <- result$p.mix
log.lik <- result$log.lik
# Break if the log-likelihood improves for less than tol * n.
if (log.lik - log.lik.prev < tol * length(x)) {
break
}    }
return(
list(lambda=lambda, p.mix=p.mix)
)
}
#   [2] Initialize the parameter values and execute the EM-algorithm.
#       Initialization
#           We initialize `lambda.init` to be equidistant values
#           in (min(x), max(x)) and `p.mix.init` to be uniform over
#           the K components.
lambda.init <- min(x) + 1:K * (max(x) - min(x)) / (K + 1)
p.mix.init <- rep(1 / K, K)
#       Run the EM-algorithm with the initialized values by calling the function
#       you implemented.
result <- em.alg(x, lambda.init, p.mix.init)
print(result)
# You should obtain (either exactly or close to it):
# $lambda
# [1]  3.084971 10.251163
# $p.mix
# [1] 0.8044016 0.1955984
rm(list=ls())
# Load required libraries
library(tidyverse)
library(StatsBombR)
# Set working directory (optional)
setwd("~/Desktop/BSE/Term 1/Statistical Modeling and Inference/Project/Data/archive (2)")
# Step 1: Fetch competition data and filter for La Liga seasons
Comps <- FreeCompetitions() %>%
filter(competition_name == "La Liga" &
season_name %in% c("2020/2021", "2019/2020", "2018/2019", "2017/2018", "2016/2017"))
# Step 2: Fetch matches for all filtered competitions
Matches <- FreeMatches(Comps)
# Step 3: Fetch and clean all event-level data for these matches
combined_data <- free_allevents(MatchesDF = Matches, Parallel = TRUE) %>%
allclean()
# Step 4: Export the combined data to a single CSV file
write.csv(combined_data, "la_liga_combined_events.csv", row.names = FALSE)
str(combined_data)
library(tidyverse)
# Function to flatten list-type columns in a data frame
flatten_df <- function(df) {
df %>%
mutate(across(where(is.list), ~ map_chr(., toString)))  # Convert list columns to strings
}
# Step 4: Export the combined data to a single CSV file
write.csv(flatten_df(combined_data), "la_liga_combined_events.csv", row.names = FALSE)
library(tidyverse)
library(dplyr)
library(purrr)
# Function to flatten list-type columns in a data frame
flatten_df <- function(df) {
df %>%
mutate(across(where(is.list), ~ map_chr(., toString)))  # Convert list columns to strings
}
# Apply the function to your data
combined_data_flat <- flatten_df(combined_data)
# Step 4: Export the combined data to a single CSV file
write.csv(flatten_df(combined_data), "la_liga_combined_events.csv", row.names = FALSE)
cat("All La Liga season data has been combined and saved to 'la_liga_combined_events.csv'\n")
